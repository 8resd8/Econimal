{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b29564e-32bb-46dc-9b02-b0b7ebf8b43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['description', 'tagged_description'], dtype='object')\n",
      "                   description              tagged_description emoji\n",
      "0  ì—ì–´ì»¨ì„ 26ë„ë¡œ ì„¤ì •í•˜ê³  í•„ìš”í•œ ì‹œê°„ì—ë§Œ ì¼ ë‹¤.  â„ï¸ ì—ì–´ì»¨ì„ 26ë„ë¡œ ì„¤ì •í•˜ê³  í•„ìš”í•œ ì‹œê°„ì—ë§Œ ì¼ ë‹¤.     â„\n",
      "1      ì§‘ ì•ˆì˜ ëª¨ë“  ì¡°ëª…ì„ í˜•ê´‘ë“±ìœ¼ë¡œ ìœ ì§€í•œë‹¤.       ğŸ’¡ ì§‘ ì•ˆì˜ ëª¨ë“  ì¡°ëª…ì„ í˜•ê´‘ë“±ìœ¼ë¡œ ìœ ì§€í•œë‹¤.     ğŸ’¡\n",
      "2   ì„¸íƒë¬¼ì„ ëª¨ì•„ì„œ ì„¸íƒê¸°ë¥¼ ì£¼ 2~3íšŒë§Œ ëŒë¦°ë‹¤.     ğŸ§ºì„¸íƒë¬¼ì„ ëª¨ì•„ì„œ ì„¸íƒê¸°ë¥¼ ì£¼ 2~3íšŒë§Œ ëŒë¦°ë‹¤.     ğŸ§º\n",
      "3       ì „ê¸°ë°¥ì†¥ ë³´ì˜¨ ê¸°ëŠ¥ì„ í•˜ë£¨ ì¢…ì¼ ì¼œë‘”ë‹¤.        ğŸ”Œ ì „ê¸°ë°¥ì†¥ ë³´ì˜¨ ê¸°ëŠ¥ì„ í•˜ë£¨ ì¢…ì¼ ì¼œë‘”ë‹¤.     ğŸ”Œ\n",
      "4     ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì „ìì œí’ˆì˜ í”ŒëŸ¬ê·¸ë¥¼ ë½‘ì•„ë‘”ë‹¤.      ğŸ”Œ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì „ìì œí’ˆì˜ í”ŒëŸ¬ê·¸ë¥¼ ë½‘ì•„ë‘”ë‹¤.     ğŸ”Œ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "data = pd.read_csv(\"./bulkdata/add_emoji.csv\")\n",
    "print(data.columns)  # ì»¬ëŸ¼ í™•ì¸: description, tagged_description\n",
    "\n",
    "# tagged_description ì»¬ëŸ¼ì˜ ë§¨ ì• ê¸€ìë¥¼ ì´ëª¨ì§€ë¡œ ê°„ì£¼í•˜ì—¬ ìƒˆë¡œìš´ ì»¬ëŸ¼ ìƒì„±\n",
    "data['emoji'] = data['tagged_description'].str[0]\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "print(data[['description', 'tagged_description', 'emoji']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1849944-6cda-4c63-9492-58218e2455c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¼ë²¨ ì¸ì½”ë”© ê²°ê³¼: {'â„': 0, 'ğŸ’¡': 1, 'ğŸ§º': 2, 'ğŸ”Œ': 3, 'ğŸ’§': 4, 'ğŸ—‘': 5, 'ğŸ”¥': 6, 'ğŸ›¢': 7}\n"
     ]
    }
   ],
   "source": [
    "# ì´ëª¨ì§€ ë¼ë²¨ ì¸ì½”ë”© (ìœ ë‹ˆí¬í•œ ì´ëª¨ì§€ì— ë²ˆí˜¸ ë¶€ì—¬)\n",
    "emoji_to_idx = {emoji: idx for idx, emoji in enumerate(data['emoji'].unique())}\n",
    "idx_to_emoji = {idx: emoji for emoji, idx in emoji_to_idx.items()}\n",
    "\n",
    "# ë¼ë²¨ ì»¬ëŸ¼ ì¶”ê°€\n",
    "data['label'] = data['emoji'].apply(lambda x: emoji_to_idx[x])\n",
    "\n",
    "print(\"ë¼ë²¨ ì¸ì½”ë”© ê²°ê³¼:\", emoji_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "465889b1-f04f-4a00-af2e-569c84dfe185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ì„ íƒ\n",
    "model_name = \"paraphrase-MiniLM-L6-v2\"\n",
    "embedder = SentenceTransformer(model_name)\n",
    "\n",
    "# description ì»¬ëŸ¼ì— ëŒ€í•´ ì„ë² ë”© ê³„ì‚° í›„ ì»¬ëŸ¼ì— ì €ì¥\n",
    "data['embedding'] = data['description'].apply(lambda x: embedder.encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bed7d18-3a88-4faf-ab55-b574b19c2b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class EmojiDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.embeddings = list(df['embedding'])\n",
    "        self.labels = list(df['label'])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        embedding = torch.tensor(self.embeddings[idx], dtype=torch.float)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return embedding, label\n",
    "\n",
    "dataset = EmojiDataset(data)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1eeabadb-a3af-481f-b2f8-17ede28b3041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11416801810264587\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class EmojiClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(EmojiClassifier, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# ì„ë² ë”© ë²¡í„°ì˜ ì°¨ì›ê³¼ ì´ëª¨ì§€ í´ë˜ìŠ¤ ìˆ˜ ì„¤ì •\n",
    "input_dim = len(data['embedding'].iloc[0])\n",
    "num_classes = len(emoji_to_idx)\n",
    "classifier = EmojiClassifier(input_dim, num_classes)\n",
    "\n",
    "# í•™ìŠµ ì„¤ì •\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-3)\n",
    "num_epochs = 1000  # ë°ì´í„° ì–‘ì— ë”°ë¼ ì¡°ì •\n",
    "\n",
    "# í•™ìŠµ ë£¨í”„\n",
    "avg_loss = 0\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for batch_embeddings, batch_labels in dataloader:\n",
    "        outputs = classifier(batch_embeddings)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    # print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "print(avg_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bb0e880-a8c4-40aa-abfc-026123948b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¶ˆëŸ¬ì˜¨ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\n",
      "   eco_answer_id  eco_quiz_id                  description  exp  \\\n",
      "0              5          164  ì—ì–´ì»¨ì„ 26ë„ë¡œ ì„¤ì •í•˜ê³  í•„ìš”í•œ ì‹œê°„ì—ë§Œ ì¼ ë‹¤.   20   \n",
      "1              6          164      ì§‘ ì•ˆì˜ ëª¨ë“  ì¡°ëª…ì„ í˜•ê´‘ë“±ìœ¼ë¡œ ìœ ì§€í•œë‹¤.  -15   \n",
      "2              7          164  ğŸ§ºì„¸íƒë¬¼ì„ ëª¨ì•„ì„œ ì„¸íƒê¸°ë¥¼ ì£¼ 2~3íšŒë§Œ ëŒë¦°ë‹¤.   12   \n",
      "3              8          164       ì „ê¸°ë°¥ì†¥ ë³´ì˜¨ ê¸°ëŠ¥ì„ í•˜ë£¨ ì¢…ì¼ ì¼œë‘”ë‹¤.   -8   \n",
      "4              9          164     ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì „ìì œí’ˆì˜ í”ŒëŸ¬ê·¸ë¥¼ ë½‘ì•„ë‘”ë‹¤.   10   \n",
      "\n",
      "            created_at           updated_at  \n",
      "0  2025-03-24 13:50:20  2025-03-24 13:50:20  \n",
      "1  2025-03-24 13:50:20  2025-03-24 13:50:20  \n",
      "2  2025-03-24 13:50:20  2025-03-31 10:58:28  \n",
      "3  2025-03-24 13:50:20  2025-03-24 13:50:20  \n",
      "4  2025-03-24 13:50:20  2025-03-24 13:50:20  \n",
      "\n",
      "ì˜ˆì¸¡ ê²°ê³¼ (description, predicted_emoji):\n",
      "                   description predicted_emoji\n",
      "0  ì—ì–´ì»¨ì„ 26ë„ë¡œ ì„¤ì •í•˜ê³  í•„ìš”í•œ ì‹œê°„ì—ë§Œ ì¼ ë‹¤.               â„\n",
      "1      ì§‘ ì•ˆì˜ ëª¨ë“  ì¡°ëª…ì„ í˜•ê´‘ë“±ìœ¼ë¡œ ìœ ì§€í•œë‹¤.               ğŸ’¡\n",
      "2  ğŸ§ºì„¸íƒë¬¼ì„ ëª¨ì•„ì„œ ì„¸íƒê¸°ë¥¼ ì£¼ 2~3íšŒë§Œ ëŒë¦°ë‹¤.               ğŸ§º\n",
      "3       ì „ê¸°ë°¥ì†¥ ë³´ì˜¨ ê¸°ëŠ¥ì„ í•˜ë£¨ ì¢…ì¼ ì¼œë‘”ë‹¤.               ğŸ”Œ\n",
      "4     ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì „ìì œí’ˆì˜ í”ŒëŸ¬ê·¸ë¥¼ ë½‘ì•„ë‘”ë‹¤.               ğŸ”Œ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. ìƒˆ CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° (ì¹¼ëŸ¼ ì´ë¦„ì´ \"description\"ì„ì„ í™•ì¸)\n",
    "val_data = pd.read_csv(\"./bulkdata/db-2025-04-01.csv\")\n",
    "print(\"ë¶ˆëŸ¬ì˜¨ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "print(val_data.head())\n",
    "\n",
    "# 2. í•™ìŠµëœ ëª¨ë¸(ì˜ˆ: classifier, embedder, idx_to_emoji)ì´ ì´ë¯¸ ì¡´ì¬í•œë‹¤ê³  ê°€ì •í•˜ê³ , \n",
    "#    \"description\" ì¹¼ëŸ¼ì˜ í…ìŠ¤íŠ¸ë¥¼ ëŒ€ìƒìœ¼ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "\n",
    "def predict_emoji(sentence):\n",
    "    with torch.no_grad():\n",
    "        # ë¬¸ì¥ ì„ë² ë”© ê³„ì‚° (ê¸°ì¡´ì— ì‚¬ìš©í•œ embedder)\n",
    "        embedding = embedder.encode(sentence)\n",
    "        embedding_tensor = torch.tensor(embedding, dtype=torch.float)\n",
    "        # ëª¨ë¸ ì˜ˆì¸¡\n",
    "        output = classifier(embedding_tensor)\n",
    "        predicted_index = torch.argmax(output).item()\n",
    "        return idx_to_emoji[predicted_index]\n",
    "\n",
    "# 3. description ì¹¼ëŸ¼ì— ëŒ€í•´ ì˜ˆì¸¡ ìˆ˜í–‰í•˜ì—¬ ìƒˆë¡œìš´ ì»¬ëŸ¼ì— ì €ì¥\n",
    "val_data['predicted_emoji'] = val_data['description'].apply(lambda x: predict_emoji(x))\n",
    "\n",
    "# 4. ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\nì˜ˆì¸¡ ê²°ê³¼ (description, predicted_emoji):\")\n",
    "print(val_data[['description', 'predicted_emoji']].head())\n",
    "\n",
    "# 5. ì›í•œë‹¤ë©´ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "val_data.to_csv(\"./bulkdata/db_with_predictions.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "513c3e9d-a4b7-4815-b449-60fd8216ffd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì •ë‹µ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\n",
      "   eco_answer_id  eco_quiz_id                  description  exp  \\\n",
      "0              5          164  ì—ì–´ì»¨ì„ 26ë„ë¡œ ì„¤ì •í•˜ê³  í•„ìš”í•œ ì‹œê°„ì—ë§Œ ì¼ ë‹¤.   20   \n",
      "1              6          164      ì§‘ ì•ˆì˜ ëª¨ë“  ì¡°ëª…ì„ í˜•ê´‘ë“±ìœ¼ë¡œ ìœ ì§€í•œë‹¤.  -15   \n",
      "2              7          164  ğŸ§ºì„¸íƒë¬¼ì„ ëª¨ì•„ì„œ ì„¸íƒê¸°ë¥¼ ì£¼ 2~3íšŒë§Œ ëŒë¦°ë‹¤.   12   \n",
      "3              8          164       ì „ê¸°ë°¥ì†¥ ë³´ì˜¨ ê¸°ëŠ¥ì„ í•˜ë£¨ ì¢…ì¼ ì¼œë‘”ë‹¤.   -8   \n",
      "4              9          164     ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì „ìì œí’ˆì˜ í”ŒëŸ¬ê·¸ë¥¼ ë½‘ì•„ë‘”ë‹¤.   10   \n",
      "\n",
      "            created_at           updated_at answer_emoji  \n",
      "0  2025-03-24 13:50:20  2025-03-24 13:50:20            â„  \n",
      "1  2025-03-24 13:50:20  2025-03-24 13:50:20            ğŸ’¡  \n",
      "2  2025-03-24 13:50:20  2025-03-31 10:58:28            ğŸ§º  \n",
      "3  2025-03-24 13:50:20  2025-03-24 13:50:20            ğŸ”Œ  \n",
      "4  2025-03-24 13:50:20  2025-03-24 13:50:20            ğŸ”Œ  \n",
      "\n",
      "ì „ì²´ ì •í™•ë„: 41.05%\n",
      "\n",
      "ì˜¤ë‹µ ì‚¬ë¡€ (descripttion, answer_emoji, predicted_emoji):\n",
      "                      description answer_emoji predicted_emoji\n",
      "5      ìŒì‹ë¬¼ ì°Œêº¼ê¸°ë¥¼ ë¬¼ë¡œ ì”»ì–´ í•˜ìˆ˜êµ¬ì— í˜ë ¤ë³´ë‚¸ë‹¤.            ğŸ¥˜               ğŸ’§\n",
      "7   ê¸°ë¦„ ë¬»ì€ í›„ë¼ì´íŒ¬ì„ í‚¤ì¹œíƒ€ì›”ë¡œ ë‹¦ì€ í›„ ì„¤ê±°ì§€í•œë‹¤.            ğŸ’§               ğŸ”¥\n",
      "10           ìš”ë¦¬ ì¤‘ ëƒ„ë¹„ ëšœê»‘ì„ ë®ê³  ì¡°ë¦¬í•œë‹¤.            ğŸ›¢               ğŸ§º\n",
      "15                      íƒ„ì†Œë°°ì¶œê¶Œ ê±°ë˜ì œ           âš–ï¸               ğŸ§º\n",
      "16                         ì—ë„ˆì§€í‘œì‹œì œ           âš–ï¸               ğŸ§º\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. ì •ë‹µ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "gt_data = pd.read_csv(\"./bulkdata/db_with_answer.csv\")\n",
    "print(\"ì •ë‹µ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "print(gt_data.head())\n",
    "\n",
    "# 2. description ì¹¼ëŸ¼ì„ ëŒ€ìƒìœ¼ë¡œ ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "# ì´ì „ì— ì •ì˜í•œ predict_emoji í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "gt_data['predicted_emoji'] = gt_data['description'].apply(lambda x: predict_emoji(x))\n",
    "\n",
    "# 3. ì˜ˆì¸¡ ê²°ê³¼ì™€ ì •ë‹µ ë¹„êµ\n",
    "gt_data['correct'] = gt_data['predicted_emoji'] == gt_data['answer_emoji']\n",
    "\n",
    "# ì „ì²´ ì •í™•ë„ ê³„ì‚°\n",
    "accuracy = gt_data['correct'].mean()\n",
    "print(f\"\\nì „ì²´ ì •í™•ë„: {accuracy*100:.2f}%\")\n",
    "\n",
    "# 4. ì˜¤ë‹µ ì‚¬ë¡€ ì¶œë ¥ (ì›í•˜ëŠ” ê²½ìš°)\n",
    "mismatches = gt_data[~gt_data['correct']]\n",
    "print(\"\\nì˜¤ë‹µ ì‚¬ë¡€ (description, answer_emoji, predicted_emoji):\")\n",
    "print(mismatches[['description', 'answer_emoji', 'predicted_emoji']].head())\n",
    "\n",
    "# 5. ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥ (ì›í•˜ëŠ” ê²½ìš°)\n",
    "gt_data.to_csv(\"db_with_predictions_and_answer_comparison.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01f128d7-1c5b-4ac4-9f3a-e3f874caa16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¶ˆëŸ¬ì˜¨ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\n",
      "   eco_answer_id  eco_quiz_id                  description  exp  \\\n",
      "0              5          164  ì—ì–´ì»¨ì„ 26ë„ë¡œ ì„¤ì •í•˜ê³  í•„ìš”í•œ ì‹œê°„ì—ë§Œ ì¼ ë‹¤.   20   \n",
      "1              6          164      ì§‘ ì•ˆì˜ ëª¨ë“  ì¡°ëª…ì„ í˜•ê´‘ë“±ìœ¼ë¡œ ìœ ì§€í•œë‹¤.  -15   \n",
      "2              7          164  ğŸ§ºì„¸íƒë¬¼ì„ ëª¨ì•„ì„œ ì„¸íƒê¸°ë¥¼ ì£¼ 2~3íšŒë§Œ ëŒë¦°ë‹¤.   12   \n",
      "3              8          164       ì „ê¸°ë°¥ì†¥ ë³´ì˜¨ ê¸°ëŠ¥ì„ í•˜ë£¨ ì¢…ì¼ ì¼œë‘”ë‹¤.   -8   \n",
      "4              9          164     ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì „ìì œí’ˆì˜ í”ŒëŸ¬ê·¸ë¥¼ ë½‘ì•„ë‘”ë‹¤.   10   \n",
      "\n",
      "            created_at           updated_at answer_emoji  \n",
      "0  2025-03-24 13:50:20  2025-03-24 13:50:20            â„  \n",
      "1  2025-03-24 13:50:20  2025-03-24 13:50:20            ğŸ’¡  \n",
      "2  2025-03-24 13:50:20  2025-03-31 10:58:28            ğŸ§º  \n",
      "3  2025-03-24 13:50:20  2025-03-24 13:50:20            ğŸ”Œ  \n",
      "4  2025-03-24 13:50:20  2025-03-24 13:50:20            ğŸ”Œ  \n",
      "ë¼ë²¨ ì¸ì½”ë”© ê²°ê³¼: {'â„': 0, 'ğŸ’¡': 1, 'ğŸ§º': 2, 'ğŸ”Œ': 3, 'ğŸ¥˜': 4, 'ğŸ’§': 5, 'ğŸ—‘': 6, 'ğŸ›¢': 7, 'ğŸ”¥': 8, 'âš–ï¸': 9}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1. CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "train_data = pd.read_csv(\"./bulkdata/db_with_answer.csv\")\n",
    "print(\"ë¶ˆëŸ¬ì˜¨ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "print(train_data.head())\n",
    "\n",
    "# 2. answer_emojië¥¼ ë¼ë²¨ë¡œ ì‚¬ìš©\n",
    "#    ê³ ìœ í•œ ì´ëª¨ì§€ì— ë²ˆí˜¸ë¥¼ ë¶€ì—¬í•˜ì—¬ ë¼ë²¨ ì¸ì½”ë”© ì§„í–‰\n",
    "emoji_to_idx = {emoji: idx for idx, emoji in enumerate(train_data[\"answer_emoji\"].unique())}\n",
    "idx_to_emoji = {idx: emoji for emoji, idx in emoji_to_idx.items()}\n",
    "train_data['label'] = train_data['answer_emoji'].apply(lambda x: emoji_to_idx[x])\n",
    "print(\"ë¼ë²¨ ì¸ì½”ë”© ê²°ê³¼:\", emoji_to_idx)\n",
    "\n",
    "# 3. ì„ë² ë”© ê³„ì‚°ì„ ìœ„í•œ ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "embedder = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
    "\n",
    "# 'description' ì¹¼ëŸ¼ì˜ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©í•˜ê³  ìƒˆë¡œìš´ ì¹¼ëŸ¼ì— ì €ì¥\n",
    "train_data['embedding'] = train_data['description'].apply(lambda x: embedder.encode(x))\n",
    "\n",
    "# 4. PyTorch Dataset ì •ì˜\n",
    "class EmojiDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.embeddings = list(df['embedding'])\n",
    "        self.labels = list(df['label'])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # ì„ë² ë”© ë²¡í„°ì™€ ë¼ë²¨ì„ í…ì„œë¡œ ë³€í™˜\n",
    "        embedding = torch.tensor(self.embeddings[idx], dtype=torch.float)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return embedding, label\n",
    "\n",
    "dataset = EmojiDataset(train_data)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 5. ë¶„ë¥˜ê¸° ëª¨ë¸ ì •ì˜ (ë‹¨ìˆœ ì„ í˜• ë¶„ë¥˜ê¸°)\n",
    "class EmojiClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(EmojiClassifier, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "input_dim = len(train_data['embedding'].iloc[0])  # ì„ë² ë”© ë²¡í„° ì°¨ì›\n",
    "num_classes = len(emoji_to_idx)\n",
    "classifier = EmojiClassifier(input_dim, num_classes)\n",
    "\n",
    "# 6. í•™ìŠµ ì„¤ì •\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-3)\n",
    "num_epochs = 1000  # ì—í¬í¬ ìˆ˜ëŠ” ë°ì´í„° ì–‘ì— ë”°ë¼ ì¡°ì •\n",
    "\n",
    "# 7. ì¬í•™ìŠµ (Training Loop)\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for batch_embeddings, batch_labels in dataloader:\n",
    "        outputs = classifier(batch_embeddings)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    # print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# ì¬í•™ìŠµ ì™„ë£Œ í›„, ëª¨ë¸ì„ ì €ì¥í•˜ê±°ë‚˜ ì¶”ê°€ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eec98923-f728-4f27-861d-b16f7b4ee781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  answer_emoji                  description                  combined_text\n",
      "0            â„  ì—ì–´ì»¨ì„ 26ë„ë¡œ ì„¤ì •í•˜ê³  í•„ìš”í•œ ì‹œê°„ì—ë§Œ ì¼ ë‹¤.  â„ ì—ì–´ì»¨ì„ 26ë„ë¡œ ì„¤ì •í•˜ê³  í•„ìš”í•œ ì‹œê°„ì—ë§Œ ì¼ ë‹¤.\n",
      "1            ğŸ’¡      ì§‘ ì•ˆì˜ ëª¨ë“  ì¡°ëª…ì„ í˜•ê´‘ë“±ìœ¼ë¡œ ìœ ì§€í•œë‹¤.      ğŸ’¡ ì§‘ ì•ˆì˜ ëª¨ë“  ì¡°ëª…ì„ í˜•ê´‘ë“±ìœ¼ë¡œ ìœ ì§€í•œë‹¤.\n",
      "2            ğŸ§º  ğŸ§ºì„¸íƒë¬¼ì„ ëª¨ì•„ì„œ ì„¸íƒê¸°ë¥¼ ì£¼ 2~3íšŒë§Œ ëŒë¦°ë‹¤.  ğŸ§º ğŸ§ºì„¸íƒë¬¼ì„ ëª¨ì•„ì„œ ì„¸íƒê¸°ë¥¼ ì£¼ 2~3íšŒë§Œ ëŒë¦°ë‹¤.\n",
      "3            ğŸ”Œ       ì „ê¸°ë°¥ì†¥ ë³´ì˜¨ ê¸°ëŠ¥ì„ í•˜ë£¨ ì¢…ì¼ ì¼œë‘”ë‹¤.       ğŸ”Œ ì „ê¸°ë°¥ì†¥ ë³´ì˜¨ ê¸°ëŠ¥ì„ í•˜ë£¨ ì¢…ì¼ ì¼œë‘”ë‹¤.\n",
      "4            ğŸ”Œ     ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì „ìì œí’ˆì˜ í”ŒëŸ¬ê·¸ë¥¼ ë½‘ì•„ë‘”ë‹¤.     ğŸ”Œ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì „ìì œí’ˆì˜ í”ŒëŸ¬ê·¸ë¥¼ ë½‘ì•„ë‘”ë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(\"./bulkdata/db_with_answer.csv\")\n",
    "\n",
    "# answer_emojiì™€ descripttionì„ ê²°í•©í•˜ì—¬ ìƒˆë¡œìš´ ì»¬ëŸ¼ ìƒì„±\n",
    "# (ì–‘ìª½ ì‚¬ì´ì— ê³µë°± ì¶”ê°€)\n",
    "df['combined_text'] = df['answer_emoji'] + \" \" + df['description']\n",
    "\n",
    "# ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°\n",
    "print(df[['answer_emoji', 'description', 'combined_text']].head())\n",
    "\n",
    "# ìƒˆë¡œìš´ CSV íŒŒì¼ë¡œ ì €ì¥ (ì›í•˜ëŠ” ê²½ë¡œ ë° íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥)\n",
    "df.to_csv(\"./bulkdata/db_with_combined_text.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e738d8-2758-4633-9e5b-920eeb7552fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
