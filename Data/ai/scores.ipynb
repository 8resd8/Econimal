{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fcb4bf2-cd0b-4b25-8159-705e68d3a877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일 저장 완료\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./bulkdata/final_descriptions_with_scores.csv\")\n",
    "\n",
    "# 최종 DataFrame에서 description 컬럼만 선택\n",
    "final_description_df = df[['description']]\n",
    "\n",
    "# CSV 파일로 저장 (파일 경로는 필요에 따라 수정)\n",
    "final_description_df.to_csv(\"./bulkdata/descriptions.csv\", index=False)\n",
    "\n",
    "print(\"CSV 파일 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e3cb5f6-dd0c-4773-925c-6fa28b6b5730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            description  PN\n",
      "0         ❄ 에어컨을 26도로 설정하고 필요한 시간에만 켠다.   1\n",
      "1             💡 집 안의 모든 조명을 형광등으로 유지한다.  -1\n",
      "2          🧺 세탁물을 모아서 세탁기를 주 2~3회만 돌린다.   1\n",
      "3              🔌 전기밥솥 보온 기능을 하루 종일 켜둔다.  -1\n",
      "4            🔌 사용하지 않는 전자제품의 플러그를 뽑아둔다.   1\n",
      "5          🥘 음식물 찌꺼기를 물로 씻어 하수구에 흘려보낸다.  -1\n",
      "6          💧 세제를 사용한 걸레를 흐르는 물로 오래 헹군다.  -1\n",
      "7       💧 기름 묻은 후라이팬을 키친타월로 닦은 후 설거지한다.   1\n",
      "8                 🗑 화장실에 물티슈나 기저귀를 버린다.  -1\n",
      "9      💧 남은 약이나 폐기물을 약국 또는 지정 수거함에 버린다.   1\n",
      "10               🛢 요리 중 냄비 뚜껑을 덮고 조리한다.   1\n",
      "11          🔥 겨울철 보일러를 하루 종일 틀어놓고 외출한다.  -1\n",
      "12     🔥 보일러 온도는 낮추고, 온수는 필요한 만큼만 사용한다.   1\n",
      "13         🛢 가스레인지에 불꽃이 냄비 바깥으로 퍼지게 켠다.   1\n",
      "14  🛢 가스 누출 점검을 정기적으로 하고, 오래된 호스를 교체한다.   1\n",
      "15         🧺 세탁물을 모아서 세탁기를 주 2~3회만 돌린다.   1\n",
      "16            💡 집 안의 모든 조명을 형광등으로 유지한다.  -1\n",
      "17                        🧺 매일 세탁기를 돌린다   1\n",
      "18             🔌 전기밥솥 보온 기능을 하루 종일 켜둔다.  -1\n",
      "19                      💡 불필요한 조명을 꺼둔다.  -1\n",
      "20                      ❄ 냉장고 문을 자주 연다.   1\n",
      "21                ❄ 에어컨 온도를 항상 낮게 유지한다.  -1\n",
      "22                       🔌 컴퓨터를 항상 켜둔다.  -1\n",
      "23                   🛢 요리 시 냄비 뚜껑을 덮는다.   1\n",
      "24              🔥 물을 끓일 때 항상 최대 불로 끓인다.   1\n",
      "25                 🛢 가스를 켜둔 채 다른 일을 한다.   1\n",
      "26                   🛢 매일 오랜 시간 난방을 한다.   1\n",
      "27                      💧 양치질 시 물을 잠근다.   1\n",
      "28                       💧 목욕탕을 매일 채운다.   1\n",
      "29                        💧 물을 많이 사용한다.   1\n",
      "30               💧 세차할 때 항상 물을 계속 틀어둔다.   1\n",
      "31           🔥 난방을 적절히 낮추고 옷을 따뜻하게 입는다.   1\n",
      "32                      ❄ 창문을 항상 열어 둔다.   1\n",
      "33                  🛢 집 전체를 하루 종일 난방한다.  -1\n",
      "34               🛢 난방기를 항상 최고 온도로 설정한다.   1\n",
      "35                      🗑 다회용 물병을 사용한다.   1\n",
      "36                    🗑 일회용 컵을 자주 사용한다.   1\n",
      "37              🗑 플라스틱 포장된 제품을 자주 구매한다.   1\n",
      "38                     🗑 비닐봉지를 자주 사용한다.   1\n",
      "39                       🗑 필요한 양만 조리한다.   1\n",
      "40                    🥘 항상 음식을 넉넉히 만든다.   1\n",
      "41                        🥘 음식을 자주 버린다.  -1\n",
      "42                  🥘 남은 음식 보관을 하지 않는다.   1\n",
      "43                   🚲 자전거 또는 걷기를 이용한다.   1\n",
      "44                        🚗 차를 자주 이용한다.   1\n",
      "45                  🚗 가까운 거리도 자동차로 다닌다.   1\n",
      "46                   🚗 대중교통 이용을 하지 않는다.   1\n",
      "47                         🗑 양면 인쇄를 한다.   1\n",
      "48                   🗑 종이를 일회용으로만 사용한다.   1\n",
      "49                       🗑 종이를 많이 사용한다.   1\n",
      "50                        🗑 한쪽 면만 인쇄한다.   1\n",
      "51          🌳 대기오염 감소와 에너지를 줄이는 효과가 있다.   1\n",
      "52                🚗 주차 공간 부족 문제를 심화시킨다.   1\n",
      "53      🚗 도로 확장을 유발하여 환경 파괴 원인이 될 수 있다.   1\n",
      "54       🛢 화석 연료 사용을 강제해 지구 온난화를 가속화한다.   1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "import io\n",
    "\n",
    "# 1. 학습 데이터 재정의 (사용자 레이블 및 피드백)\n",
    "user_labels_data = \"\"\"\n",
    "❄ 에어컨을 26도로 설정하고 필요한 시간에만 켠다.,1\n",
    "💡 집 안의 모든 조명을 형광등으로 유지한다.,-1\n",
    "🧺 세탁물을 모아서 세탁기를 주 2~3회만 돌린다.,1\n",
    "🔌 전기밥솥 보온 기능을 하루 종일 켜둔다.,-1\n",
    "🔌 사용하지 않는 전자제품의 플러그를 뽑아둔다.,1\n",
    "🥘 음식물 찌꺼기를 물로 씻어 하수구에 흘려보낸다.,-1\n",
    "💧 세제를 사용한 걸레를 흐르는 물로 오래 헹군다.,-1\n",
    "💧 기름 묻은 후라이팬을 키친타월로 닦은 후 설거지한다.,1\n",
    "🗑 화장실에 물티슈나 기저귀를 버린다.,-1\n",
    "💧 남은 약이나 폐기물을 약국 또는 지정 수거함에 버린다.,1\n",
    "🛢 요리 중 냄비 뚜껑을 덮고 조리한다.,1\n",
    "🔥 겨울철 보일러를 하루 종일 틀어놓고 외출한다.,-1\n",
    "\"\"\"\n",
    "\n",
    "# 데이터프레임 생성\n",
    "user_df = pd.read_csv(io.StringIO(user_labels_data), header=None, names=[\"description\", \"score\"])\n",
    "\n",
    "# 학습 데이터 결합 후, NaN 값 제거\n",
    "updated_train_data = updated_train_data.dropna(subset=[\"user_score\"])\n",
    "\n",
    "# 2. TF-IDF 벡터화 및 Ridge 회귀 모델 재학습\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(updated_train_data[\"description\"])\n",
    "y_train = updated_train_data[\"user_score\"].astype(float)\n",
    "\n",
    "reg_model = Ridge()\n",
    "reg_model.fit(X_train, y_train)\n",
    "\n",
    "# 3. CSV 파일 불러오기 및 모델 예측\n",
    "df_reloaded = pd.read_csv(\"./bulkdata/descriptions.csv\")\n",
    "\n",
    "# description 칼럼 기반 예측 수행\n",
    "X_all = vectorizer.transform(df_reloaded[\"description\"])\n",
    "reg_predictions = reg_model.predict(X_all)\n",
    "\n",
    "# 이진 긍/부정 판단: 0보다 크면 1(긍정), 그렇지 않으면 -1(부정)\n",
    "df_reloaded[\"PN\"] = [1 if score > 0 else -1 for score in reg_predictions]\n",
    "\n",
    "# 결과 미리 보기\n",
    "print(df_reloaded.head(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b07e429-2e27-463c-8b62-0fdd032bdc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "적용 완료: descriptions_with_lexicon.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 긍정 단어 100개 (각 단어는 최대 3글자)\n",
    "positive_words_100 = [\n",
    "    \"절약\", \"효율\", \"친환\", \"재활\", \"보존\", \"절감\", \"최소\", \"지속\", \"절전\", \"저탄\",\n",
    "    \"개선\", \"정화\", \"순환\", \"재생\", \"녹색\", \"청정\", \"산림\", \"해양\", \"자연\", \"중립\",\n",
    "    \"다양\", \"에코\", \"혁신\", \"신재\", \"녹성\", \"회복\", \"도시\", \"경영\", \"투자\", \"정책\",\n",
    "    \"자원\", \"소비\", \"의식\", \"스마트\", \"녹기\", \"물절\", \"친농\", \"자립\", \"실천\", \"행동\",\n",
    "    \"지구\", \"환기\", \"환원\", \"감소\", \"조절\", \"에너\", \"산업\", \"녹산\", \"바람\", \"태양\",\n",
    "    \"수력\", \"풍력\", \"전환\", \"저배\", \"녹전\", \"친건\", \"친소\", \"친화\", \"녹업\", \"신기\",\n",
    "    \"산보\", \"해보\", \"친업\", \"전력\", \"녹율\", \"녹원\", \"친도\", \"녹지\", \"청원\", \"재순\",\n",
    "    \"친생\", \"환산\", \"탄감\", \"녹실\", \"녹환\", \"에녹\", \"신환\", \"자환\", \"청환\", \"녹창\",\n",
    "    \"에친\", \"효보\", \"에보\", \"산청\", \"녹청\", \"에신\", \"자경\", \"친자\", \"산지\", \"해지\",\n",
    "    \"자지\", \"에경\", \"에정\", \"재개\", \"녹개\", \"순보\", \"에순\", \"친합\", \"자합\", \"녹합\"\n",
    "]\n",
    "\n",
    "# 부정 단어 100개 (각 단어는 최대 3글자)\n",
    "negative_words_100 = [\n",
    "    \"낭비\", \"과다\", \"무분\", \"상시\", \"불필\", \"과도\", \"과소\", \"오염\", \"폐기\", \"파괴\",\n",
    "    \"배출\", \"독성\", \"부적\", \"비효\", \"무절\", \"자낭\", \"남용\", \"무용\", \"소음\", \"미세\",\n",
    "    \"화석\", \"비재\", \"독물\", \"온실\", \"과열\", \"불균\", \"불안\", \"폐물\", \"에낭\", \"무계\",\n",
    "    \"파적\", \"해로\", \"위협\", \"불안\", \"부실\", \"부정\", \"자형\", \"부실운\", \"오남\", \"무효\",\n",
    "    \"독배\", \"폐증\", \"소과\", \"불친\", \"비도\", \"위험\", \"낭성\", \"비합\", \"대오\", \"수오\",\n",
    "    \"토오\", \"소공\", \"오물\", \"해오\", \"기악\", \"불투\", \"산폐\", \"산파\", \"자파\", \"대질\",\n",
    "    \"자남\", \"화출\", \"유해\", \"폐수\", \"악취\", \"기유\", \"생파\", \"피해\", \"쓰범\", \"미폭\",\n",
    "    \"독폐\", \"불법\", \"불광\", \"비위\", \"무책\", \"폐부\", \"온과\", \"온난\", \"공해\", \"규미\",\n",
    "    \"피증\", \"재불\", \"무추\", \"쓰문\", \"도열\", \"온변\", \"위기\", \"생행\", \"불합\", \"비불\",\n",
    "    \"부퇴\", \"폐악\", \"불폐\", \"비낭\", \"비오\", \"과배\", \"부오\", \"비폐\", \"지오\", \"산오\"\n",
    "]\n",
    "\n",
    "def lexicon_score(text, pos_list, neg_list):\n",
    "    \"\"\"텍스트 내에 포함된 긍정 단어와 부정 단어의 개수를 세어 점수를 산출합니다.\"\"\"\n",
    "    pos_count = sum(1 for word in pos_list if word in text)\n",
    "    neg_count = sum(1 for word in neg_list if word in text)\n",
    "    return pos_count - neg_count\n",
    "\n",
    "# CSV 파일 불러오기 (파일 경로를 실제 경로에 맞게 수정하세요)\n",
    "df = pd.read_csv(\"./bulkdata/descriptions.csv\")\n",
    "\n",
    "# 각 문장에 대해 사전 기반 점수 계산 (lex_score)\n",
    "df[\"lex_score\"] = df[\"description\"].apply(lambda x: lexicon_score(x, positive_words_100, negative_words_100))\n",
    "\n",
    "# 결과 CSV 파일로 저장 (예: descriptions_with_lexicon.csv)\n",
    "df.to_csv(\"./bulkdata/descriptions_with_lexicon.csv\", index=False)\n",
    "\n",
    "print(\"적용 완료: descriptions_with_lexicon.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05b455f0-cf8a-441d-b895-1716716f4bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SSAFY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\SSAFY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\SSAFY\\.cache\\huggingface\\hub\\models--sentence-transformers--distiluse-base-multilingual-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            description  lex_score  PN_final\n",
      "0         ❄ 에어컨을 26도로 설정하고 필요한 시간에만 켠다.          0         1\n",
      "1             💡 집 안의 모든 조명을 형광등으로 유지한다.          0         1\n",
      "2          🧺 세탁물을 모아서 세탁기를 주 2~3회만 돌린다.          0         1\n",
      "3              🔌 전기밥솥 보온 기능을 하루 종일 켜둔다.          0         1\n",
      "4            🔌 사용하지 않는 전자제품의 플러그를 뽑아둔다.          0        -1\n",
      "5          🥘 음식물 찌꺼기를 물로 씻어 하수구에 흘려보낸다.          0        -1\n",
      "6          💧 세제를 사용한 걸레를 흐르는 물로 오래 헹군다.          0         1\n",
      "7       💧 기름 묻은 후라이팬을 키친타월로 닦은 후 설거지한다.          0         1\n",
      "8                 🗑 화장실에 물티슈나 기저귀를 버린다.          0        -1\n",
      "9      💧 남은 약이나 폐기물을 약국 또는 지정 수거함에 버린다.         -1        -1\n",
      "10               🛢 요리 중 냄비 뚜껑을 덮고 조리한다.          0        -1\n",
      "11          🔥 겨울철 보일러를 하루 종일 틀어놓고 외출한다.          0        -1\n",
      "12     🔥 보일러 온도는 낮추고, 온수는 필요한 만큼만 사용한다.          0         1\n",
      "13         🛢 가스레인지에 불꽃이 냄비 바깥으로 퍼지게 켠다.          0        -1\n",
      "14  🛢 가스 누출 점검을 정기적으로 하고, 오래된 호스를 교체한다.          0         1\n",
      "15         🧺 세탁물을 모아서 세탁기를 주 2~3회만 돌린다.          0         1\n",
      "16            💡 집 안의 모든 조명을 형광등으로 유지한다.          0         1\n",
      "17                        🧺 매일 세탁기를 돌린다          0         1\n",
      "18             🔌 전기밥솥 보온 기능을 하루 종일 켜둔다.          0         1\n",
      "19                      💡 불필요한 조명을 꺼둔다.         -1        -1\n",
      "최종 결과 저장 완료: descriptions_with_PN_final.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 긍정 단어 100개 (각 단어는 최대 3글자)\n",
    "positive_words_100 = [\n",
    "    \"절약\", \"효율\", \"친환\", \"재활\", \"보존\", \"절감\", \"최소\", \"지속\", \"절전\", \"저탄\",\n",
    "    \"개선\", \"정화\", \"순환\", \"재생\", \"녹색\", \"청정\", \"산림\", \"해양\", \"자연\", \"중립\",\n",
    "    \"다양\", \"에코\", \"혁신\", \"신재\", \"녹성\", \"회복\", \"도시\", \"경영\", \"투자\", \"정책\",\n",
    "    \"자원\", \"소비\", \"의식\", \"스마트\", \"녹기\", \"물절\", \"친농\", \"자립\", \"실천\", \"행동\",\n",
    "    \"지구\", \"환기\", \"환원\", \"감소\", \"조절\", \"에너\", \"산업\", \"녹산\", \"바람\", \"태양\",\n",
    "    \"수력\", \"풍력\", \"전환\", \"저배\", \"녹전\", \"친건\", \"친소\", \"친화\", \"녹업\", \"신기\",\n",
    "    \"산보\", \"해보\", \"친업\", \"전력\", \"녹율\", \"녹원\", \"친도\", \"녹지\", \"청원\", \"재순\",\n",
    "    \"친생\", \"환산\", \"탄감\", \"녹실\", \"녹환\", \"에녹\", \"신환\", \"자환\", \"청환\", \"녹창\",\n",
    "    \"에친\", \"효보\", \"에보\", \"산청\", \"녹청\", \"에신\", \"자경\", \"친자\", \"산지\", \"해지\",\n",
    "    \"자지\", \"에경\", \"에정\", \"재개\", \"녹개\", \"순보\", \"에순\", \"친합\", \"자합\", \"녹합\"\n",
    "]\n",
    "\n",
    "# 부정 단어 100개 (각 단어는 최대 3글자)\n",
    "negative_words_100 = [\n",
    "    \"낭비\", \"과다\", \"무분\", \"상시\", \"불필\", \"과도\", \"과소\", \"오염\", \"폐기\", \"파괴\",\n",
    "    \"배출\", \"독성\", \"부적\", \"비효\", \"무절\", \"자낭\", \"남용\", \"무용\", \"소음\", \"미세\",\n",
    "    \"화석\", \"비재\", \"독물\", \"온실\", \"과열\", \"불균\", \"불안\", \"폐물\", \"에낭\", \"무계\",\n",
    "    \"파적\", \"해로\", \"위협\", \"불안\", \"부실\", \"부정\", \"자형\", \"부실운\", \"오남\", \"무효\",\n",
    "    \"독배\", \"폐증\", \"소과\", \"불친\", \"비도\", \"위험\", \"낭성\", \"비합\", \"대오\", \"수오\",\n",
    "    \"토오\", \"소공\", \"오물\", \"해오\", \"기악\", \"불투\", \"산폐\", \"산파\", \"자파\", \"대질\",\n",
    "    \"자남\", \"화출\", \"유해\", \"폐수\", \"악취\", \"기유\", \"생파\", \"피해\", \"쓰범\", \"미폭\",\n",
    "    \"독폐\", \"불법\", \"불광\", \"비위\", \"무책\", \"폐부\", \"온과\", \"온난\", \"공해\", \"규미\",\n",
    "    \"피증\", \"재불\", \"무추\", \"쓰문\", \"도열\", \"온변\", \"위기\", \"생행\", \"불합\", \"비불\",\n",
    "    \"부퇴\", \"폐악\", \"불폐\", \"비낭\", \"비오\", \"과배\", \"부오\", \"비폐\", \"지오\", \"산오\"\n",
    "]\n",
    "\n",
    "def lexicon_score(text, pos_list, neg_list):\n",
    "    \"\"\"텍스트 내 긍정/부정 단어 개수를 세어 점수를 반환합니다.\"\"\"\n",
    "    pos_count = sum(1 for word in pos_list if word in text)\n",
    "    neg_count = sum(1 for word in neg_list if word in text)\n",
    "    return pos_count - neg_count\n",
    "\n",
    "# CSV 파일 불러오기 (파일 경로를 실제 경로에 맞게 수정)\n",
    "df = pd.read_csv(\"./bulkdata/descriptions.csv\")\n",
    "\n",
    "# 각 문장에 대해 사전 기반 점수 계산 (lex_score)\n",
    "df[\"lex_score\"] = df[\"description\"].apply(lambda x: lexicon_score(x, positive_words_100, negative_words_100))\n",
    "\n",
    "# sentence-transformers 모델 로드 (다국어 지원 모델 사용)\n",
    "# 한국어의 경우, 'distiluse-base-multilingual-cased' 또는 'paraphrase-multilingual-MiniLM-L12-v2'와 같이 다국어 모델을 권장합니다.\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased')\n",
    "\n",
    "# 긍정 단어 및 부정 단어의 임베딩 계산 (모델에 존재하는 단어 모두 사용)\n",
    "pos_embs = [model.encode(word) for word in positive_words_100]\n",
    "avg_pos_emb = np.mean(pos_embs, axis=0) if pos_embs else None\n",
    "\n",
    "neg_embs = [model.encode(word) for word in negative_words_100]\n",
    "avg_neg_emb = np.mean(neg_embs, axis=0) if neg_embs else None\n",
    "\n",
    "def assign_label_sentence_transformers(text):\n",
    "    \"\"\"문장의 임베딩을 구한 후, 긍정/부정 평균 임베딩과의 코사인 유사도를 비교하여 라벨을 반환합니다.\"\"\"\n",
    "    text_emb = model.encode(text)\n",
    "    pos_sim = cosine_similarity(text_emb.reshape(1, -1), avg_pos_emb.reshape(1, -1))[0][0] if avg_pos_emb is not None else 0\n",
    "    neg_sim = cosine_similarity(text_emb.reshape(1, -1), avg_neg_emb.reshape(1, -1))[0][0] if avg_neg_emb is not None else 0\n",
    "    return 1 if pos_sim > neg_sim else -1\n",
    "\n",
    "def compute_final_label(row):\n",
    "    # 사전 기반 점수가 0이 아니면 그 결과 사용, 0이면 sentence-transformers 기반 유사도 판단\n",
    "    if row[\"lex_score\"] != 0:\n",
    "        return 1 if row[\"lex_score\"] > 0 else -1\n",
    "    else:\n",
    "        return assign_label_sentence_transformers(row[\"description\"])\n",
    "\n",
    "# 최종 라벨(PN_final) 부여\n",
    "df[\"PN_final\"] = df.apply(compute_final_label, axis=1)\n",
    "\n",
    "# 결과 확인 (상위 20행 출력)\n",
    "print(df.head(20))\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "df.to_csv(\"./bulkdata/descriptions_with_PN_final.csv\", index=False)\n",
    "print(\"최종 결과 저장 완료: descriptions_with_PN_final.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e934b452-9c2d-4f96-ac4f-1658206629c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 컬럼: Index(['description', 'score', 'PN'], dtype='object')\n",
      "예측 결과: -1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1. CSV 파일에서 트레이닝 데이터 로드\n",
    "#    파일에는 'description'과 'PN' 컬럼이 있다고 가정합니다.\n",
    "df_train = pd.read_csv(\"./bulkdata/descriptions_with_PN.csv\")\n",
    "print(\"데이터셋 컬럼:\", df_train.columns)\n",
    "\n",
    "# 2. 사전학습된 SentenceTransformer 모델 로드 (다국어 지원)\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased')\n",
    "\n",
    "# 3. 학습 데이터에 대해 임베딩 생성\n",
    "#    각 문장을 모델을 이용해 벡터화합니다.\n",
    "descriptions = df_train['description'].tolist()\n",
    "X_train = model.encode(descriptions)\n",
    "y_train = df_train['PN'].values  # 라벨: 1 (긍정), -1 (부정)\n",
    "\n",
    "# 4. 간단한 분류기(로지스틱 회귀) 학습\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 5. 새로운 문장을 입력받아 예측 결과를 반환하는 함수 정의\n",
    "def predict_sentiment(sentence):\n",
    "    \"\"\"\n",
    "    입력된 문장에 대해 긍정(1) 또는 부정(-1) 라벨을 반환합니다.\n",
    "    \n",
    "    Parameters:\n",
    "        sentence (str): 예측할 문장\n",
    "        \n",
    "    Returns:\n",
    "        int: 예측된 라벨 (1 또는 -1)\n",
    "    \"\"\"\n",
    "    embedding = model.encode([sentence])\n",
    "    pred = clf.predict(embedding)\n",
    "    return int(pred[0])\n",
    "\n",
    "# 예시: 테스트 문장 예측\n",
    "test_sentence = \"이 제품은 정말 효율적이고 환경에도 좋아요.\"\n",
    "result = predict_sentiment(test_sentence)\n",
    "print(\"예측 결과:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "342ffab0-b5f1-4cf3-9b21-16ae9510f3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 컬럼: Index(['description', 'score', 'PN'], dtype='object')\n",
      "== Lexicon/Embedding 기반 예측 결과와 정답(PN) 비교 ==\n",
      "전체 정확도: 56.36%\n",
      "분류 리포트:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.69      0.57      0.62        35\n",
      "           1       0.42      0.55      0.48        20\n",
      "\n",
      "    accuracy                           0.56        55\n",
      "   macro avg       0.56      0.56      0.55        55\n",
      "weighted avg       0.59      0.56      0.57        55\n",
      "\n",
      "혼동 행렬:\n",
      "[[20 15]\n",
      " [ 9 11]]\n",
      "== 분류기 학습 결과 (학습 데이터 평가) ==\n",
      "전체 정확도: 67.27%\n",
      "분류 리포트:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.66      1.00      0.80        35\n",
      "           1       1.00      0.10      0.18        20\n",
      "\n",
      "    accuracy                           0.67        55\n",
      "   macro avg       0.83      0.55      0.49        55\n",
      "weighted avg       0.78      0.67      0.57        55\n",
      "\n",
      "테스트 문장: 이 제품은 정말 효율적이고 환경에도 좋아요.\n",
      "예측 결과: -1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ── 1. 기본 단어 리스트 ──\n",
    "positive_words_100 = [\n",
    "    \"절약\", \"효율\", \"친환\", \"재활\", \"보존\", \"절감\", \"최소\", \"지속\", \"절전\", \"저탄\",\n",
    "    \"개선\", \"정화\", \"순환\", \"재생\", \"녹색\", \"청정\", \"산림\", \"해양\", \"자연\", \"중립\",\n",
    "    \"다양\", \"에코\", \"혁신\", \"신재\", \"녹성\", \"회복\", \"도시\", \"경영\", \"투자\", \"정책\",\n",
    "    \"자원\", \"소비\", \"의식\", \"스마트\", \"녹기\", \"물절\", \"친농\", \"자립\", \"실천\", \"행동\",\n",
    "    \"지구\", \"환기\", \"환원\", \"감소\", \"조절\", \"에너\", \"산업\", \"녹산\", \"바람\", \"태양\",\n",
    "    \"수력\", \"풍력\", \"전환\", \"저배\", \"녹전\", \"친건\", \"친소\", \"친화\", \"녹업\", \"신기\",\n",
    "    \"산보\", \"해보\", \"친업\", \"전력\", \"녹율\", \"녹원\", \"친도\", \"녹지\", \"청원\", \"재순\",\n",
    "    \"친생\", \"환산\", \"탄감\", \"녹실\", \"녹환\", \"에녹\", \"신환\", \"자환\", \"청환\", \"녹창\",\n",
    "    \"에친\", \"효보\", \"에보\", \"산청\", \"녹청\", \"에신\", \"자경\", \"친자\", \"산지\", \"해지\",\n",
    "    \"자지\", \"에경\", \"에정\", \"재개\", \"녹개\", \"순보\", \"에순\", \"친합\", \"자합\", \"녹합\"\n",
    "]\n",
    "\n",
    "negative_words_100 = [\n",
    "    \"낭비\", \"과다\", \"무분\", \"상시\", \"불필\", \"과도\", \"과소\", \"오염\", \"폐기\", \"파괴\",\n",
    "    \"배출\", \"독성\", \"부적\", \"비효\", \"무절\", \"자낭\", \"남용\", \"무용\", \"소음\", \"미세\",\n",
    "    \"화석\", \"비재\", \"독물\", \"온실\", \"과열\", \"불균\", \"불안\", \"폐물\", \"에낭\", \"무계\",\n",
    "    \"파적\", \"해로\", \"위협\", \"불안\", \"부실\", \"부정\", \"자형\", \"부실운\", \"오남\", \"무효\",\n",
    "    \"독배\", \"폐증\", \"소과\", \"불친\", \"비도\", \"위험\", \"낭성\", \"비합\", \"대오\", \"수오\",\n",
    "    \"토오\", \"소공\", \"오물\", \"해오\", \"기악\", \"불투\", \"산폐\", \"산파\", \"자파\", \"대질\",\n",
    "    \"자남\", \"화출\", \"유해\", \"폐수\", \"악취\", \"기유\", \"생파\", \"피해\", \"쓰범\", \"미폭\",\n",
    "    \"독폐\", \"불법\", \"불광\", \"비위\", \"무책\", \"폐부\", \"온과\", \"온난\", \"공해\", \"규미\",\n",
    "    \"피증\", \"재불\", \"무추\", \"쓰문\", \"도열\", \"온변\", \"위기\", \"생행\", \"불합\", \"비불\",\n",
    "    \"부퇴\", \"폐악\", \"불폐\", \"비낭\", \"비오\", \"과배\", \"부오\", \"비폐\", \"지오\", \"산오\"\n",
    "]\n",
    "\n",
    "# ── 2. 추가 단어 설정 (사용자 정의) ──\n",
    "additional_positive_words = [\"신뢰\", \"품질\"]   # 추가 긍정 단어\n",
    "additional_negative_words = [\"불만\", \"문제\"]     # 추가 부정 단어\n",
    "\n",
    "# 기본 리스트와 추가 단어를 합침\n",
    "positive_words = positive_words_100 + additional_positive_words\n",
    "negative_words = negative_words_100 + additional_negative_words\n",
    "\n",
    "def lexicon_score(text, pos_list, neg_list):\n",
    "    \"\"\"\n",
    "    텍스트 내 긍정 단어와 부정 단어 등장 횟수를 비교하여 점수를 반환합니다.\n",
    "    \"\"\"\n",
    "    pos_count = sum(1 for word in pos_list if word in text)\n",
    "    neg_count = sum(1 for word in neg_list if word in text)\n",
    "    return pos_count - neg_count\n",
    "\n",
    "# ── 3. CSV 파일 로드 및 정답 라벨(PN) 활용 ──\n",
    "# 파일에는 최소한 'description'과 정답 라벨인 'PN' 컬럼이 있어야 합니다.\n",
    "df = pd.read_csv(\"./bulkdata/descriptions_with_PN.csv\")\n",
    "print(\"데이터셋 컬럼:\", df.columns)\n",
    "\n",
    "# lexicon 기반 점수 계산 (추가 단어까지 반영)\n",
    "df[\"lex_score\"] = df[\"description\"].apply(lambda x: lexicon_score(x, positive_words, negative_words))\n",
    "\n",
    "# ── 4. SentenceTransformer 모델 로드 및 임베딩 기반 라벨 산출 ──\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased')\n",
    "\n",
    "# 긍정/부정 단어들의 임베딩 평균 계산 (모든 단어 사용)\n",
    "pos_embs = [model.encode(word) for word in positive_words]\n",
    "avg_pos_emb = np.mean(pos_embs, axis=0) if pos_embs else None\n",
    "\n",
    "neg_embs = [model.encode(word) for word in negative_words]\n",
    "avg_neg_emb = np.mean(neg_embs, axis=0) if neg_embs else None\n",
    "\n",
    "def assign_label_sentence_transformers(text):\n",
    "    \"\"\"\n",
    "    문장의 임베딩을 구한 후, 긍정/부정 평균 임베딩과의 코사인 유사도를 비교하여 라벨을 반환합니다.\n",
    "    \"\"\"\n",
    "    text_emb = model.encode(text)\n",
    "    pos_sim = cosine_similarity(text_emb.reshape(1, -1), avg_pos_emb.reshape(1, -1))[0][0] if avg_pos_emb is not None else 0\n",
    "    neg_sim = cosine_similarity(text_emb.reshape(1, -1), avg_neg_emb.reshape(1, -1))[0][0] if avg_neg_emb is not None else 0\n",
    "    return 1 if pos_sim > neg_sim else -1\n",
    "\n",
    "def compute_final_label(row):\n",
    "    \"\"\"\n",
    "    lexicon 기반 점수가 0이 아니면 해당 결과를 사용하고, 0이면 임베딩 유사도 비교 결과를 사용합니다.\n",
    "    \"\"\"\n",
    "    if row[\"lex_score\"] != 0:\n",
    "        return 1 if row[\"lex_score\"] > 0 else -1\n",
    "    else:\n",
    "        return assign_label_sentence_transformers(row[\"description\"])\n",
    "\n",
    "# lexicon 및 임베딩 기반으로 최종 라벨(PN_final) 산출\n",
    "df[\"PN_final\"] = df.apply(compute_final_label, axis=1)\n",
    "\n",
    "# ── 5. 정답(PN)과 우리 방법(PN_final) 비교 평가 ──\n",
    "print(\"== Lexicon/Embedding 기반 예측 결과와 정답(PN) 비교 ==\")\n",
    "print(\"전체 정확도: {:.2f}%\".format(accuracy_score(df[\"PN\"], df[\"PN_final\"])*100))\n",
    "print(\"분류 리포트:\")\n",
    "print(classification_report(df[\"PN\"], df[\"PN_final\"]))\n",
    "print(\"혼동 행렬:\")\n",
    "print(confusion_matrix(df[\"PN\"], df[\"PN_final\"]))\n",
    "\n",
    "# ── 6. 로지스틱 회귀 분류기 학습 (문장 임베딩을 이용, 정답 라벨 PN 사용) ──\n",
    "descriptions = df[\"description\"].tolist()\n",
    "X_train = model.encode(descriptions)\n",
    "y_train = df[\"PN\"].values  # 정답 라벨 사용\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# ── 7. 분류기 평가 (학습 데이터에서 예시) ──\n",
    "pred_train = clf.predict(X_train)\n",
    "print(\"== 분류기 학습 결과 (학습 데이터 평가) ==\")\n",
    "print(\"전체 정확도: {:.2f}%\".format(accuracy_score(y_train, pred_train)*100))\n",
    "print(\"분류 리포트:\")\n",
    "print(classification_report(y_train, pred_train))\n",
    "\n",
    "# ── 8. 예측 함수 정의 ──\n",
    "def predict_sentiment(sentence):\n",
    "    \"\"\"\n",
    "    입력된 문장에 대해 학습된 분류기를 이용해 감성 라벨(1: 긍정, -1: 부정)을 예측하여 반환합니다.\n",
    "    \n",
    "    Parameters:\n",
    "        sentence (str): 예측할 문장\n",
    "        \n",
    "    Returns:\n",
    "        int: 예측된 감성 라벨 (1 또는 -1)\n",
    "    \"\"\"\n",
    "    embedding = model.encode([sentence])\n",
    "    pred = clf.predict(embedding)\n",
    "    return int(pred[0])\n",
    "\n",
    "# ── 9. 테스트 예시 ──\n",
    "test_sentence = \"이 제품은 정말 효율적이고 환경에도 좋아요.\"\n",
    "result = predict_sentiment(test_sentence)\n",
    "print(\"테스트 문장:\", test_sentence)\n",
    "print(\"예측 결과:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50f96365-1c1d-4a52-9cd4-5e47791dd531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 컬럼: Index(['description', 'score', 'PN'], dtype='object')\n",
      "== Lexicon/Embedding 기반 예측 결과와 정답(PN) 비교 ==\n",
      "전체 정확도: 56.36%\n",
      "분류 리포트:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.69      0.57      0.62        35\n",
      "           1       0.42      0.55      0.48        20\n",
      "\n",
      "    accuracy                           0.56        55\n",
      "   macro avg       0.56      0.56      0.55        55\n",
      "weighted avg       0.59      0.56      0.57        55\n",
      "\n",
      "혼동 행렬:\n",
      "[[20 15]\n",
      " [ 9 11]]\n",
      "== SVM 분류기 학습 결과 (학습 데이터 평가) ==\n",
      "전체 정확도: 67.27%\n",
      "분류 리포트:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.66      1.00      0.80        35\n",
      "           1       1.00      0.10      0.18        20\n",
      "\n",
      "    accuracy                           0.67        55\n",
      "   macro avg       0.83      0.55      0.49        55\n",
      "weighted avg       0.78      0.67      0.57        55\n",
      "\n",
      "테스트 문장: 이 제품은 정말 효율적이고 환경에도 좋아요.\n",
      "예측 결과: -1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ── 1. 기본 단어 리스트 ──\n",
    "positive_words_100 = [\n",
    "    \"절약\", \"효율\", \"친환\", \"재활\", \"보존\", \"절감\", \"최소\", \"지속\", \"절전\", \"저탄\",\n",
    "    \"개선\", \"정화\", \"순환\", \"재생\", \"녹색\", \"청정\", \"산림\", \"해양\", \"자연\", \"중립\",\n",
    "    \"다양\", \"에코\", \"혁신\", \"신재\", \"녹성\", \"회복\", \"도시\", \"경영\", \"투자\", \"정책\",\n",
    "    \"자원\", \"소비\", \"의식\", \"스마트\", \"녹기\", \"물절\", \"친농\", \"자립\", \"실천\", \"행동\",\n",
    "    \"지구\", \"환기\", \"환원\", \"감소\", \"조절\", \"에너\", \"산업\", \"녹산\", \"바람\", \"태양\",\n",
    "    \"수력\", \"풍력\", \"전환\", \"저배\", \"녹전\", \"친건\", \"친소\", \"친화\", \"녹업\", \"신기\",\n",
    "    \"산보\", \"해보\", \"친업\", \"전력\", \"녹율\", \"녹원\", \"친도\", \"녹지\", \"청원\", \"재순\",\n",
    "    \"친생\", \"환산\", \"탄감\", \"녹실\", \"녹환\", \"에녹\", \"신환\", \"자환\", \"청환\", \"녹창\",\n",
    "    \"에친\", \"효보\", \"에보\", \"산청\", \"녹청\", \"에신\", \"자경\", \"친자\", \"산지\", \"해지\",\n",
    "    \"자지\", \"에경\", \"에정\", \"재개\", \"녹개\", \"순보\", \"에순\", \"친합\", \"자합\", \"녹합\"\n",
    "]\n",
    "\n",
    "negative_words_100 = [\n",
    "    \"낭비\", \"과다\", \"무분\", \"상시\", \"불필\", \"과도\", \"과소\", \"오염\", \"폐기\", \"파괴\",\n",
    "    \"배출\", \"독성\", \"부적\", \"비효\", \"무절\", \"자낭\", \"남용\", \"무용\", \"소음\", \"미세\",\n",
    "    \"화석\", \"비재\", \"독물\", \"온실\", \"과열\", \"불균\", \"불안\", \"폐물\", \"에낭\", \"무계\",\n",
    "    \"파적\", \"해로\", \"위협\", \"불안\", \"부실\", \"부정\", \"자형\", \"부실운\", \"오남\", \"무효\",\n",
    "    \"독배\", \"폐증\", \"소과\", \"불친\", \"비도\", \"위험\", \"낭성\", \"비합\", \"대오\", \"수오\",\n",
    "    \"토오\", \"소공\", \"오물\", \"해오\", \"기악\", \"불투\", \"산폐\", \"산파\", \"자파\", \"대질\",\n",
    "    \"자남\", \"화출\", \"유해\", \"폐수\", \"악취\", \"기유\", \"생파\", \"피해\", \"쓰범\", \"미폭\",\n",
    "    \"독폐\", \"불법\", \"불광\", \"비위\", \"무책\", \"폐부\", \"온과\", \"온난\", \"공해\", \"규미\",\n",
    "    \"피증\", \"재불\", \"무추\", \"쓰문\", \"도열\", \"온변\", \"위기\", \"생행\", \"불합\", \"비불\",\n",
    "    \"부퇴\", \"폐악\", \"불폐\", \"비낭\", \"비오\", \"과배\", \"부오\", \"비폐\", \"지오\", \"산오\"\n",
    "]\n",
    "\n",
    "# ── 2. 추가 단어 설정 (사용자 정의) ──\n",
    "additional_positive_words = [\"신뢰\", \"품질\"]   # 추가 긍정 단어\n",
    "additional_negative_words = [\"불만\", \"문제\"]     # 추가 부정 단어\n",
    "\n",
    "# 기본 리스트와 추가 단어를 합침\n",
    "positive_words = positive_words_100 + additional_positive_words\n",
    "negative_words = negative_words_100 + additional_negative_words\n",
    "\n",
    "def lexicon_score(text, pos_list, neg_list):\n",
    "    \"\"\"\n",
    "    텍스트 내 긍정 단어와 부정 단어 등장 횟수를 비교하여 점수를 반환합니다.\n",
    "    \"\"\"\n",
    "    pos_count = sum(1 for word in pos_list if word in text)\n",
    "    neg_count = sum(1 for word in neg_list if word in text)\n",
    "    return pos_count - neg_count\n",
    "\n",
    "# ── 3. CSV 파일 로드 및 정답 라벨(PN) 활용 ──\n",
    "# 파일에는 'description'과 정답 라벨 'PN' 컬럼이 있어야 합니다.\n",
    "df = pd.read_csv(\"./bulkdata/descriptions_with_PN.csv\")\n",
    "print(\"데이터셋 컬럼:\", df.columns)\n",
    "\n",
    "# lexicon 기반 점수 계산 (추가 단어까지 반영)\n",
    "df[\"lex_score\"] = df[\"description\"].apply(lambda x: lexicon_score(x, positive_words, negative_words))\n",
    "\n",
    "# ── 4. SentenceTransformer 모델 로드 및 임베딩 기반 라벨 산출 ──\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased')\n",
    "\n",
    "# 긍정/부정 단어들의 임베딩 평균 계산 (모든 단어 사용)\n",
    "pos_embs = [model.encode(word) for word in positive_words]\n",
    "avg_pos_emb = np.mean(pos_embs, axis=0) if pos_embs else None\n",
    "\n",
    "neg_embs = [model.encode(word) for word in negative_words]\n",
    "avg_neg_emb = np.mean(neg_embs, axis=0) if neg_embs else None\n",
    "\n",
    "def assign_label_sentence_transformers(text):\n",
    "    \"\"\"\n",
    "    문장의 임베딩을 구한 후, 긍정/부정 평균 임베딩과의 코사인 유사도를 비교하여 라벨을 반환합니다.\n",
    "    \"\"\"\n",
    "    text_emb = model.encode(text)\n",
    "    pos_sim = cosine_similarity(text_emb.reshape(1, -1), avg_pos_emb.reshape(1, -1))[0][0] if avg_pos_emb is not None else 0\n",
    "    neg_sim = cosine_similarity(text_emb.reshape(1, -1), avg_neg_emb.reshape(1, -1))[0][0] if avg_neg_emb is not None else 0\n",
    "    return 1 if pos_sim > neg_sim else -1\n",
    "\n",
    "def compute_final_label(row):\n",
    "    \"\"\"\n",
    "    lexicon 기반 점수가 0이 아니면 해당 결과를 사용하고, 0이면 임베딩 유사도 비교 결과를 사용합니다.\n",
    "    \"\"\"\n",
    "    if row[\"lex_score\"] != 0:\n",
    "        return 1 if row[\"lex_score\"] > 0 else -1\n",
    "    else:\n",
    "        return assign_label_sentence_transformers(row[\"description\"])\n",
    "\n",
    "# lexicon 및 임베딩 기반으로 최종 라벨(PN_final) 산출\n",
    "df[\"PN_final\"] = df.apply(compute_final_label, axis=1)\n",
    "\n",
    "# ── 5. 정답(PN)과 우리 방법(PN_final) 비교 평가 ──\n",
    "print(\"== Lexicon/Embedding 기반 예측 결과와 정답(PN) 비교 ==\")\n",
    "print(\"전체 정확도: {:.2f}%\".format(accuracy_score(df[\"PN\"], df[\"PN_final\"]) * 100))\n",
    "print(\"분류 리포트:\")\n",
    "print(classification_report(df[\"PN\"], df[\"PN_final\"]))\n",
    "print(\"혼동 행렬:\")\n",
    "print(confusion_matrix(df[\"PN\"], df[\"PN_final\"]))\n",
    "\n",
    "# ── 6. SVM 분류기 학습 (문장 임베딩을 이용, 정답 라벨 PN 사용) ──\n",
    "descriptions = df[\"description\"].tolist()\n",
    "X_train = model.encode(descriptions)\n",
    "y_train = df[\"PN\"].values  # 정답 라벨 사용\n",
    "\n",
    "# SVM 분류기 (여기서는 Linear kernel 사용)\n",
    "svm_clf = SVC(kernel='linear', probability=True)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# ── 7. 분류기 평가 (학습 데이터 평가) ──\n",
    "pred_train = svm_clf.predict(X_train)\n",
    "print(\"== SVM 분류기 학습 결과 (학습 데이터 평가) ==\")\n",
    "print(\"전체 정확도: {:.2f}%\".format(accuracy_score(y_train, pred_train) * 100))\n",
    "print(\"분류 리포트:\")\n",
    "print(classification_report(y_train, pred_train))\n",
    "\n",
    "# ── 8. 예측 함수 정의 ──\n",
    "def predict_sentiment(sentence):\n",
    "    \"\"\"\n",
    "    입력된 문장에 대해 학습된 SVM 분류기를 이용해 감성 라벨(1: 긍정, -1: 부정)을 예측하여 반환합니다.\n",
    "    \n",
    "    Parameters:\n",
    "        sentence (str): 예측할 문장\n",
    "        \n",
    "    Returns:\n",
    "        int: 예측된 감성 라벨 (1 또는 -1)\n",
    "    \"\"\"\n",
    "    embedding = model.encode([sentence])\n",
    "    pred = svm_clf.predict(embedding)\n",
    "    return int(pred[0])\n",
    "\n",
    "# ── 9. 테스트 예시 ──\n",
    "test_sentence = \"이 제품은 정말 효율적이고 환경에도 좋아요.\"\n",
    "result = predict_sentiment(test_sentence)\n",
    "print(\"테스트 문장:\", test_sentence)\n",
    "print(\"예측 결과:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d5ca12c-8886-4ec7-90f2-43a7c08d614f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DatasetDict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     33\u001b[39m num_epochs = \u001b[32m3\u001b[39m\n\u001b[32m     34\u001b[39m warmup_steps = \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_dataloader) * num_epochs * \u001b[32m0.1\u001b[39m)  \u001b[38;5;66;03m# 약 10%의 warmup\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[43mmodel_ft\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_objectives\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     40\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# fine tuning 후 모델을 사용하여 예측\u001b[39;00m\n\u001b[32m     43\u001b[39m example_sentence = \u001b[33m\"\u001b[39m\u001b[33m이 제품은 정말 효율적이고 환경에도 좋아요.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sentence_transformers\\fit_mixin.py:290\u001b[39m, in \u001b[36mFitMixin.fit\u001b[39m\u001b[34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit, resume_from_checkpoint)\u001b[39m\n\u001b[32m    287\u001b[39m         dataset = dataset.add_column(\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m, labels)\n\u001b[32m    288\u001b[39m     train_dataset_dict[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m_dataset_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloader_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m] = dataset\n\u001b[32m--> \u001b[39m\u001b[32m290\u001b[39m train_dataset_dict = \u001b[43mDatasetDict\u001b[49m(train_dataset_dict)\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_default_checkpoint_dir\u001b[39m() -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    293\u001b[39m     dir_name = \u001b[33m\"\u001b[39m\u001b[33mcheckpoints/model\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'DatasetDict' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import InputExample, SentenceTransformer, SentencesDataset, losses\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "import builtins\n",
    "builtins.Dataset = Dataset\n",
    "\n",
    "# CSV 파일 로드 (예: 'description'과 정답 라벨 'PN'이 포함된 파일)\n",
    "df = pd.read_csv(\"./bulkdata/descriptions_with_PN.csv\")\n",
    "\n",
    "# InputExample 객체 생성 (정답 라벨이 -1, 1인 경우, SoftmaxLoss를 위해 0, 1로 변환)\n",
    "train_examples = []\n",
    "for idx, row in df.iterrows():\n",
    "    label = 0 if row['PN'] == -1 else 1\n",
    "    train_examples.append(InputExample(texts=[row['description']], label=label))\n",
    "\n",
    "# 사전 학습된 모델 로드\n",
    "model_ft = SentenceTransformer('distiluse-base-multilingual-cased')\n",
    "\n",
    "# SentencesDataset 및 DataLoader 준비\n",
    "train_dataset = SentencesDataset(train_examples, model_ft)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=16)\n",
    "\n",
    "# 분류를 위한 SoftmaxLoss 설정\n",
    "num_labels = 2  # 두 클래스: 0 (부정), 1 (긍정)\n",
    "train_loss = losses.SoftmaxLoss(\n",
    "    model=model_ft, \n",
    "    sentence_embedding_dimension=model_ft.get_sentence_embedding_dimension(), \n",
    "    num_labels=num_labels\n",
    ")\n",
    "\n",
    "# Fine tuning 실행\n",
    "num_epochs = 3\n",
    "warmup_steps = int(len(train_dataloader) * num_epochs * 0.1)  # 약 10%의 warmup\n",
    "model_ft.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=num_epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# fine tuning 후 모델을 사용하여 예측\n",
    "example_sentence = \"이 제품은 정말 효율적이고 환경에도 좋아요.\"\n",
    "embedding = model_ft.encode(example_sentence)\n",
    "print(\"Fine tuned embedding:\", embedding[:5])  # 임베딩의 일부 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3ebc73-579a-4640-ac87-b2d5c5c93275",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
